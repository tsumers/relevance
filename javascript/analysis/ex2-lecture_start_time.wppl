var SPEAKER_ALPHA = 2
var LISTENER_ALPHA = 1

/// DECISION PROBLEM: possible worlds, actions, and
var possibleWorlds =
    Categorical({
        ps:[1, 1],
        vs: ['5:00', '5:05']
    })

var actions = ['5:00', '5:05']

/// R(a, w)
var reward = function(a, w) {
    // arriving exactly when the lecture starts is great
    if (a === w) {
        return 1
    }

    // arriving too late is bad
    if (w === '5:00' && a === '5:05') {
        return -.5
    }

    // we showed up on time, the lecture was late.
    return 0.9

}

/// Utterances and p(w | u)
var utterances =  Infer({method: 'enumerate'}, function(){
    uniformDraw(['5:00', '5:05'])
})

var literalMeanings = {
    '5:00': function(world) { return world === '5:00'; },
    '5:05': function(world) { return world === '5:05'; }
};

///fold:
var beliefListener = function(utt) {
    return Infer({method: 'enumerate'}, function(){

        // Sample from all worlds
        var world = sample(possibleWorlds)
        var meaning = literalMeanings[utt];
        condition(meaning(world));

        return world
    })
}

var actionListener = function(utt) {

    var beliefs = beliefListener(utt)

    return Infer({method: 'enumerate'}, function(){

        var actionChoice = uniformDraw(actions)

        // marginalizing over reward in possible worlds
        // i.e. L \propto \sum_w P(w | u) e^{beta*R}
        var world = sample(beliefs)
        factor(LISTENER_ALPHA * reward(actionChoice, world))

        return actionChoice
    })
}

var truthFunc = function(utt, trueWorld){

    var worldLogProb = beliefListener(utt).score(trueWorld)

    // Use +1 / -1
    return (worldLogProb === -Infinity) ? -1 : 1

}

var speaker = function(trueWorld, lambda){

    return Infer({method: 'enumerate'}, function(){

        var utt = sample(utterances)
        var actionUtility = sum(map(function(a){
            return reward(a, trueWorld) * actionListener(utt).score(a)
        }, actions))
        var truthUtility = truthFunc(utt, trueWorld)

        var uttUtility = lambda * actionUtility + (1-lambda)*truthUtility - uttCost(utt)
        factor(SPEAKER_ALPHA * uttUtility)

        return utt
    })

}
///

var pragmaticListener = function(utt, lambda){

    return Infer({method: 'enumerate'}, function(){

        var world = sample(possibleWorlds)
        var speakerUtt = sample(speaker(world, lambda))
        condition(speakerUtt === utt)

        return world

    })

}


/// Assume longer utterances are more expensive.
var uttCost = function(utt){

    return 0

}

//console.log(JSON.stringify(speaker('5:00', 1)))

console.log('belief-only speaker draws symmetric inferences for 5:00 and 5:05')
console.log(JSON.stringify(pragmaticListener('5:00', 0)))
console.log(JSON.stringify(pragmaticListener('5:05', 0)))

console.log('\ncombined speaker draws asymmetric inferences')
console.log('5:05 less likely to be interpreted as 5:00 than vice versa')
console.log('because speaker knows being late is worse than being early')
console.log(JSON.stringify(pragmaticListener('5:00', .9)))
console.log(JSON.stringify(pragmaticListener('5:05', .9)))
